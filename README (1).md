# Multivariate Time Series Forecasting with LSTM, Transformer, and Hybrid Models

## ðŸ“Œ Overview
This project implements and compares **three deep learning architectures** â€” **LSTM**, **Transformer**, and **Hybrid LSTMâ€“Transformer** â€” for **multivariate time series forecasting** across three domains:
- **Electricity Load Forecasting** (Power Dataset)
- **Traffic Flow Prediction** (Traffic Dataset)
- **Weather Prediction** (Weather Dataset)

The models are evaluated on **accuracy**, **latency**, and **error patterns** to determine their suitability for real-world forecasting applications.

---

## ðŸ“‚ Project Structure
```
.
â”œâ”€â”€ configs/                  # YAML configuration files for each dataset/model
â”œâ”€â”€ data/                     # Downloaded datasets & processed train/val/test splits
â”‚   â”œâ”€â”€ power/
â”‚   â”œâ”€â”€ traffic/
â”‚   â””â”€â”€ weather/
â”œâ”€â”€ scripts/                  # Helper scripts for batch evaluation and analysis
â”œâ”€â”€ src/                      # Model definitions and training loop
â”‚   â”œâ”€â”€ models/               # LSTM, Transformer, Hybrid implementations
â”‚   â”œâ”€â”€ train.py              # Training entry point
â”‚   â”œâ”€â”€ model_registry.py     # Model factory
â”‚   â”œâ”€â”€ utils.py              # Utility functions
â”œâ”€â”€ references.bib            # Bibliography for the IEEE paper
â”œâ”€â”€ final_full_report.tex     # Main IEEE-format report
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ requirements.txt          # Python dependencies
```

---

## ðŸ“Š Datasets
1. **Power Dataset (UCI Electricity Load Diagrams)**  
   - Source: UCI Machine Learning Repository  
   - Hourly aggregated electricity consumption for multiple clients.
   
2. **Traffic Dataset (Monash Traffic)**  
   - Hourly road occupancy rates from multiple highway sensors.  
   
3. **Weather Dataset (Jena Climate)**  
   - Hourly temperature, pressure, humidity, wind speed, etc.

---

## ðŸ›  Preprocessing Pipeline
- Convert all columns to numeric
- Fill missing values with forward and backward fill
- Select target variable as the highest-variance series
- Select top features by variance
- Normalize using Z-score standardization
- Chronological split into **70% train**, **10% validation**, **20% test**

---

## ðŸ§  Model Architectures
### LSTM
Two stacked LSTM layers with dropout regularization, followed by a dense output layer.

### Transformer
Two encoder layers with multi-head self-attention and positional encoding.

### Hybrid LSTMâ€“Transformer
An initial LSTM layer for local patterns followed by Transformer encoder layers for global dependencies.

---

## ðŸ“ˆ Evaluation Metrics
- **MAE** â€“ Mean Absolute Error
- **RMSE** â€“ Root Mean Squared Error
- **MAPE** â€“ Mean Absolute Percentage Error
- **SMAPE** â€“ Symmetric Mean Absolute Percentage Error
- **Inference Latency** â€“ Average batch prediction time

---

## ðŸš€ Running the Project

### 1. Clone the Repository
```bash
git clone <repo_url>
cd <repo_name>
```

### 2. Create a Virtual Environment
```bash
python -m venv .venv
source .venv/bin/activate    # Linux/Mac
.venv\Scripts\activate       # Windows
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Download & Prepare Datasets
Run preprocessing scripts for each dataset:
```bash
python scripts/prep_power.py
python scripts/prep_traffic.py
python scripts/prep_weather.py
```

### 5. Train Models
Example:
```bash
python -m src.train --config configs/power.yaml
```

### 6. Batch Evaluation
```bash
python scripts/run_all.py
```

---

## ðŸ“œ Paper
The complete IEEE-format paper for this project can be found in:
- `final_full_report_with_cites.tex`
- `references.bib`

---

## ðŸ“Œ Notes
- Ensure datasets are placed in `data/` before training.
- Model checkpoints (`best.ckpt`) will be saved in `outputs/`.
- For reproducibility, all configs specify `random_seed`.

---

## ðŸ“„ License
This project is released under the MIT License.
